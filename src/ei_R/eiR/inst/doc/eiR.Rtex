\documentclass{article}

\usepackage{hyperref}

\title{eiR}
\author{Kevin Horan}


\begin{document}
\maketitle

\section{Introduction}
EiR provides an index for compound databases allowing one to
quickly find similar compounds in a very large database.

EiR works on compound databases. A compound database consists of two files.
One is the actual database data file in some format. This database, known
as the <bindb>, typically consists of actual compound data. For example,
an atom-pair database would use a <bindb> to store atom pair descriptors.
The other file is an ID database or <iddb>. This database is just a text
file, each line of which is a sequence ID used to subset the <bindb>. For
example, if the <bindb> contains 1,000 compounds, then the <iddb> can
contain at most 1,000 lines of sequential numbers from 1 to 1000. Using
this <bindb> and <iddb>, then we have a compound database for 1,000
compounds. If, for example, the <iddb> contains 500 lines of odd numbers
from 1 up to 999, then the combination of the <bindb> and the <iddb>
describes a compound database of 500 compounds. Note that <iddb> uses
1-based numbering, not 0-based. 

You may see these files under the data folder:
\begin{itemize}
	\item main.iddb : this is the main iddb. Compounds referenced in this 
         iddb will be embedded.
	\item test\_query.iddb : this file is auto-generated. It is a subset of 
         main.iddb used to perform automatic search tests in order to evaluate 
         the embedding quality.
\end{itemize}

Note that there is no requirement on what format <bindb> uses. EiR does not
utilize <bindb> directly. Instead, it passes the path to <bindb> to
the db2dbDistance function. If you use your own custom similarity
measure (see Section \ref{customization}), as long as your custom
db2dbDistance function can understand <bindb>, then it is fine.    


\section{Initialization}
An initial compound database must be created with the following command:

\begin{Scode}
   library(eiR)
   data(sdfsample)
   eiInit(sdfsample)
\end{Scode}

EiInit can take either an SDFset, or a filename.  SDF is supported
by default. Other formats can be supported through customization
(Sec. \ref{customization}). It might complain if your SDF file does not
follow the SDF specification. If this happens, you can create an
SDFset with the \texttt{read.SDFset} command and then use that
instead of the filename.  EiInit will create  a folder called
'data'. Commands should always be executed in the folder containing
this directory (ie, the parent directory of "data"), or else
specify the location of that directory with the \texttt{dir} option.

\section{Creating a Searchable Database}

In this step the compounds in the data directory will be embedded
in another space which allows for more efficient searching. The
main two parameters are $r$ and $d$. $r$ is the number of reference
compounds to use and $d$ is the dimension of the embedding space.
We have found in practice that setting $d$ to around 100 works well.
$r$ should be large enough to ``represent'' the full compound
database. 
 
To help tune these values, \texttt{eiMakeDb} will pick
\texttt{numSamples} non-reference samples which can later be used by the
\texttt{eiPerformanceTest} function.
Since this is the longest running step, a SNOW cluster can be
provided to parallelize the task.

\texttt{eiMakdDb} does its job in a job folder, named after the number of reference
compounds and the number of embedding dimensions. For example, using 300
reference compounds to generate 300-dimensional embedding ($r=300,
d=100$) will result in a job folder called run-300-100. 
The embedding result is the file matrix.<r>.<d>. In the above example,
the output would be run-300-100/matrix.300.100.


\begin{Scode}
   r<- 50
   d<- 40
   matrixFile <- eiMakeDb(r,d,numSamples=20,cl=makeCluster(1,type="SOCK",outfile=""))
\end{Scode}


\section{Queries}

As with \texttt{eiInit}, queries can be specified as an SDFset or
a filename. You need to identify the reference IDDB file, it will
be the file under the run directory ending in ``.cdb''. Then you
can perform a query as follows: 

\begin{Scode}
   #find reference IDDB file
   runDir<-paste("run",r,d,sep="-")
   matches<-dir(runDir,pattern=".cdb$",full.names=TRUE)
   refIddb = matches[1]

   #find compounds similar two each query
   eiQuery(r,d,refIddb,sdfsample[1:2],K=15)

\end{Scode}

The result will be a data frame with three columns. The first is
a query id, the second is a target, or hit, id, and the third is
the distance between them. Lsh parameters can be passed in as well,
see Section \ref{performance-tests} for more details.

\section{Performance Tests}
\label{performance-tests}

To evaluate the performance you can run:

\begin{Scode}{term=false}
   eiPerformanceTest(r,d,K=22)
\end{Scode}

This will perform a performance evaluation by testing the
embedding results in similarity search. The way this works is by
approximating 1,000 random similarity searches (determined by
data/test\_queries.iddb) by nearest neighbor search using the coordinates
from the embedding results. The search results are then compared to the
reference search results (chemical-search.results.gz). 

The comparison results are summarized in two type of files. The first
type lists the recall for different k value, k being the number of
numbers to retrieve. For example, if the recall is 70% for top-100
compound search - 70 of the 100 results are among the real top-100
compounds - then the value at line 100 is 0.7. Several relaxation ration
is used, each generating a file in this form. For instance,
recall.ratio-10 is the file listing the recalls when relaxation
ratio is 10. The other file, recall.csv, lists recalls of different
relaxation ratios in one file by limiting to selected k value. In this
CSV file, the rows correspond to different relaxation ratios, and the
columns are different k values. You will be able to pick an appropriate
relaxation ratio for the k values you are interested in.


The results for lsh-assisted search will be in
run-r-d/indexed.performance. It's a 1,000-line recall values. Each
line corresponds to one test query.  LSH search performance is
highly sensitive to your LSH parameters (K, W, M, L, T). The
default parameters are listed in the man page for
\texttt{eiPerformanceTest}. When you have your embedding result in
a matrix file, you should follow instruction on
\url{http://lshkit.sourceforge.net/dd/d2a/mplsh-tune_8cpp.html} to
find the best values for these parameters.


\section{Customization}
\label{customization}

All \texttt{eiXXXX} methods accept a \texttt{measure} parameter.
A measure object handles dealing with the compound representations
and also computing distances between compounds.
It is a list with three fields, named: dbBuilder, dbSubset, and
db2dbDistance. Each of these is a function.

As an example, here is the default measure, which works for sdf
formated files and computes distances using atompair descriptors:
\begin{Scode}
 atompairMeasure = list(
	dbBuilder = function(input,output)
		batch_sdf_parse(input,output),
	dbSubset = function(db,iddb,output)
		db_subset(db,iddb,output),
	db2dbDistance = function(db,db2=NA,iddb1=NA,iddb2=NA,file=NA)
	{
		if(!is.na(file)){
			if(is.na(db2) && ! is.na(iddb1) && ! is.na(iddb2)){
				db2db_distance2file(db,iddb1,iddb2,file)
			}else if(!is.na(db2) &&  is.na(iddb1) &&  is.na(iddb2)){
				db2db_distance2file(db,db2,file)
			}else{
				stop("bad argument list")
			}
		}else{
			if(is.na(db2) && ! is.na(iddb1) && ! is.na(iddb2)){
				return(.Call("db2db_distance_iddb",as.character(db),as.character(iddb1),as.character(iddb2)))
			}else if(!is.na(db2) &&  is.na(iddb1) &&  is.na(iddb2)){
				return(.Call("db2db_distance_db",as.character(db),as.character(db2)))
			}else{
				stop("bad argument list\n")
			}
		}
	}
)
\end{Scode}
 

\texttt{DbBuilder} transforms the raw input file into whatever
format will be used by dbSubset and db2dbDistance. It should take
the name of an input file and the name of an output file to create.

\texttt{DbSubset} extracts a subset of compounds from one file and
puts them in another file. The compounds to extract are defined by 
an IDDB file. It should take the name of a compound
file, in the format output by dbSubset, an IDDB file, and the name
of the output file

\texttt{Db2dbDistance} computes distances between compounds. There
are two ways to use this function. The first is to specify both
\texttt{db} and \texttt{db2}. This should compute all pairwise
distances between compounds in these two files. The second way is
to specify \texttt{db}, \texttt{iddb1}, and \texttt{iddb2}. In this
case distances are computed only between compounds given in the two
IDDB files. \texttt{db} should contain all compounds referenced by
the IDDB files. In both cases, the \texttt{file} can optionally be
given. If given, the output should be written to a file. The output
should be lines of whitespace separated numbers. Each line should
contain the distances of the first element of the first db against
each member of the second db. If \texttt{file} is not given, the
result should be returned as a matrix.


\begin{Scode}{echo=false,term=false}
   unlink("data",recursive=TRUE)
   unlink(runDir,recursive=TRUE)
\end{Scode}
\end{document}
