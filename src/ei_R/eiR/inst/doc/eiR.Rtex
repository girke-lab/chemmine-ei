\documentclass{article}

\usepackage{hyperref}

\title{eiR}
\author{Kevin Horan}

%\VignetteIndexEntry{eiR}

\begin{document}
\maketitle

\section{Introduction}
EiR provides an index for chemical compound databases allowing one to
quickly find similar compounds in a very large database.
To create this index, $r$ reference compounds are
selected to represent the database. Then each compound in the database
is embedded into $d$-dimensional space based on their distance to each
reference compound. This requires time linear in the size of the database, but
only needs to be done once for a database.
Within this space, Locality Sensitive Hashing (LSH)
is employed to allow sub-linear time nearest neighbor lookups.
This means that nearest neighbors can be found without doing a linear
scan through the entire compound database.
Additional compounds can be added to the database in time linear to 
the number of new compounds. No time is spend processing existing compounds,
as long as the set of reference compounds remains the same.
Given the ability to quickly find nearest neighbors, this method enables
fast clustering with the Jarvis-Pattrick algorithm as well. 
For details see ``Accelerated similarity searching and clustering of large compound sets by
geometric embedding and locality sensitive hashing.'', Cao Y, Jiang T, Girke T
Bioinformatics. 2010 Apr 1; 26(7): 953-9.

This library uses an SQL backend (SQLite by default) to store chemical 
compound definitions, either in SDF or SMILE format, as well
as descriptors. Several different kinds of descriptors can be stored for
each compound, for example, one could compute and store atom-pair and fingerprint
descriptors for each compound. The SQLite database, if used, is stored in a directory called "data".
Also in this directory is a file called "Main.iddb", which stores the id
of each compound in the current "logical" database. This allows you to
have compounds in the SQL database that are not being used, or to create
various subsets of one large SQL database. The  eiInit function is
used to create a new database, it can import data from SDF or SMILE formated
files, or an SDFset object. 

Once a database has been created, an embedding must also be created. In this
step the reference compounds are chosen and each compound is embedded into
the new space. This step creates a new directory called "run-r-d", where "r"
and "d" are the corresponding values. This is the most costly step of
the process and is handled by the eiMakeDb function. This step can be
parrallized by providing a SNOW cluster to the eiMakeDb function.

Given an embedded database, queries can be run against it with the
eiQuery function. Additional compounds can also be added to an existing
database and embedding using eiAdd. Performance tests can be run using the 
eiPerformanceTest function, and Jarvis-Patrick clustering can be done
with the eiCluster function.

EiR also provides some mechanisms to allow the user to extend the set of 
descriptor formats used and to define new distance functions.



%EiR works on compound databases. A compound database consists of two files.
%One is the actual database data file in some format. This database, known
%as the <bindb>, typically consists of actual compound data. For example,
%an atom-pair database would use a <bindb> to store atom pair descriptors.
%The other file is an ID database or <iddb>. This database is just a text
%file, each line of which is a sequence ID used to subset the <bindb>. For
%example, if the <bindb> contains 1,000 compounds, then the <iddb> can
%contain at most 1,000 lines of sequential numbers from 1 to 1000. Using
%this <bindb> and <iddb>, then we have a compound database for 1,000
%compounds. If, for example, the <iddb> contains 500 lines of odd numbers
%from 1 up to 999, then the combination of the <bindb> and the <iddb>
%describes a compound database of 500 compounds. Note that <iddb> uses
%1-based numbering, not 0-based. 
%
%You may see these files under the data folder:
%\begin{itemize}
%	\item main.iddb : this is the main iddb. Compounds referenced in this 
%         iddb will be embedded.
%	\item test\_query.iddb : this file is auto-generated. It is a subset of 
%         main.iddb used to perform automatic search tests in order to evaluate 
%         the embedding quality.
%\end{itemize}
%
%Note that there is no requirement on what format <bindb> uses. EiR does not
%utilize <bindb> directly. Instead, it passes the path to <bindb> to
%the db2dbDistance function. If you use your own custom similarity
%measure (see Section \ref{customization}), as long as your custom
%db2dbDistance function can understand <bindb>, then it is fine.    


\section{Initialization}
An initial compound database must be created with the following command:

\begin{Scode}
   library(eiR)
   data(sdfsample)
   eiInit(sdfsample[1:99])
\end{Scode}

EiInit can take either an SDFset, or a filename. If a filename is given
it must be in either SDF  or SMILE format and the format must be specified 
with the \texttt{format} paramter.  It might complain if your SDF file does not
follow the SDF specification. If this happens, you can create an
SDFset with the \texttt{read.SDFset} command and then use that
instead of the filename.  

Descriptors will also be computed at this time. The default descriptor type
is atompair. Other types can be used by setting the \texttt{descriptorType}
parameter. Currently available types are "ap" for atompair, and "fp" for
fingerprint.  The set of available descriptors can be extended, see Section
\ref{customization}.
EiInit will create  a folder called
'data'. Commands should always be executed in the folder containing
this directory (ie, the parent directory of "data"), or else
specify the location of that directory with the \texttt{dir} option.

eiInit will return a list of compound id numbers which represent the
compounds just inserted. These numbers can be used to issue queries later.

\section{Creating a Searchable Database}

In this step the compounds in the data directory will be embedded
in another space which allows for more efficient searching. The
main two parameters are $r$ and $d$. $r$ is the number of reference
compounds to use and $d$ is the dimension of the embedding space.
We have found in practice that setting $d$ to around 100 works well.
$r$ should be large enough to ``represent'' the full compound
database. 
 
To help tune these values, \texttt{eiMakeDb} will pick
\texttt{numSamples} non-reference samples which can later be used by the
\texttt{eiPerformanceTest} function.
Since this is the longest running step, a SNOW cluster can be
provided to parallelize the task.

\texttt{eiMakdDb} does its job in a job folder, named after the number of reference
compounds and the number of embedding dimensions. For example, using 300
reference compounds to generate a 300-dimensional embedding ($r=300,
d=100$) will result in a job folder called run-300-100. 
The embedding result is the file matrix.<r>.<d>. In the above example,
the output would be run-300-100/matrix.300.100.

Since more than one type of descriptor can be stored for each compound, the desired
descriptor type must be given to this function with the \texttt{descriptorType} parameter.
The default value is "ap", for atompair.  You can also specify a custom distance function that must be able to
take two descriptors in the format specified and return a distance value.

The return value is the path of the refIddb file, which is a file
containing list of referenice id values. This file is needed by other
functions.


\begin{Scode}
   library(snow)
   r<- 50
   d<- 40
   refIddb <- eiMakeDb(r,d,numSamples=20,cl=makeCluster(1,type="SOCK",outfile=""))
\end{Scode}


\section{Queries}

Queries can be given in several formats, defined by the
\texttt{format} parameter. The default format is "sdf". The 
\texttt{queries} parameter can be either an sdf file or and SDFset under
this format. Other valid values for \texttt{format} are "name" and "compound\_id".
Under these two formats the \texttt{queries} parameter is expected to
be a list of compound names (as returned by sdfid on an SDFset), or a list
of id numbers from the database, such as what is returned by the eiInit
function.

As with \texttt{eiMakeDb}, the \texttt{descriptorType} and \texttt{distance}
parameters may be given if desired. They will default to atompair.

You need to identify the reference IDDB file, it will
be returned by the eiMakeDb function. Then you
can perform a query as follows: 

\begin{Scode}

   #find compounds similar to each query
   eiQuery(r,d,refIddb,sdfsample[1:2],K=15)

\end{Scode}

The result will be a data frame with four columns. The first is
a query id, the second is a target, or hit, id, the third is the id number of 
the target, and the fourth is
the distance between the query and target. Lsh parameters can be passed in as well,
see Section \ref{performance-tests} for more details.

\section{Adding New Compounds}
New Compounds can be added to an existing database, however, the 
reference compounds cannot be changed. 
To add new compounds, use the eiAdd function. This function
is very similar to the eiQuery function, except instead of a 
\texttt{queiries} parameter, there is an \texttt{additions} parameter,
defining the compounds to be added. The format of the value of this
parameter works the same as in the eiQuery function.
For example, to add one compound from an SDFset you would do:

\begin{Scode}{term=false}
   eiAdd(r,d,refIddb,sdfsample[100])
\end{Scode}


\section{Performance Tests}
\label{performance-tests}

The eiPerforamceTest function will run several tests using some sample
data to evaluate the performace of the current embedding. It takes
the usual $r$ and $d$ parameters, as well as on option distance function
and descriptor type, to choose which set of descriptors to use. It also
takes several LSH parameters, though the defaults are usually fine. 
To evaluate the performance you can run:

\begin{Scode}{term=false}
   eiPerformanceTest(r,d,K=22)
\end{Scode}

This will perform two different tests.
The first tests the embedding results in similarity search. The way this works is by
approximating 1,000 random similarity searches (determined by
data/test\_queries.iddb) by nearest neighbor search using the coordinates
from the embedding results. The search results are then compared to the
reference search results (chemical-search.results.gz). 

The comparison results are summarized in two types of files. The first
type lists the recall for different k values, k being the number of
numbers to retrieve. These files are named as ``recall-ratio-k''.
For example, if the recall is 70\% for top-100
compound search (70 of the 100 results are among the real top-100
compounds) then the value at line 100 is 0.7. Several relaxation ratios
are used, each generating a file in this form. For instance,
recall.ratio-10 is the file listing the recalls when relaxation
ratio is 10. The other file, recall.csv, lists recalls of different
relaxation ratios in one file by limiting to selected k value. In this
CSV file, the rows correspond to different relaxation ratios, and the
columns are different k values. You will be able to pick an appropriate
relaxation ratio for the k values you are interested in.


The second test measures the performance of the Locality Sensitive Hash (LSH).
The results for lsh-assisted search will be in
run-r-d/indexed.performance. It's a 1,000-line file of recall values. Each
line corresponds to one test query.  LSH search performance is
highly sensitive to your LSH parameters (K, W, M, L, T). The
default parameters are listed in the man page for
\texttt{eiPerformanceTest}. When you have your embedding result in
a matrix file, you should follow instruction on
\url{http://lshkit.sourceforge.net/dd/d2a/mplsh-tune_8cpp.html} to
find the best values for these parameters.


\section{Customization}
\label{customization}

EiR can be extended to understand new descriptor types and new distance 
functions. New distance functions can be set in two different ways.
Any function that takes a distance parameter can be given a new 
distance function that will be used for just that call. If no
distance function is given, it will fetch a default distance
function that has been defined for the given descriptor type.
This default value can be changed using the \texttt{setDefaultDistance}
function, which takes the descriptor type and a distance function.
Once this function has been called, the new distance function will be
used for that descriptor type by all functions using a distance function.
The built-in defaults are defined as follows:
\begin{Scode}
	setDefaultDistance("ap", function(d1,d2) 1-cmp.similarity(d1,d2) )
	setDefaultDistance("fp", function(d1,d2) 1-fpSim(d1,d2) )
\end{Scode}

New descriptor types can also be added using the \texttt{addTransform}
function. These transforms are basically just ways to read descriptors from 
compound definitions, and to convert descriptors between string and object form. This conversion
is required because descriptors are stored as strings in the SQL database, but are used
by the rest of the program as objects.

There are two main components that need to be added. The
\texttt{addTransform} function takes the name of the transform and two functions,
\texttt{toString}, and \texttt{toObject}. These have slightly different
meanings depending on the component you are adding.
The first component to add 
is a transform from a chemical compound format, such as SDF, to a descriptor format,
such as atom pair (AP), in either string or object form. 
In this case the transform name should be
built with the \texttt{buildType} function, which takes the compound format
and the descriptor type as arguments. The toString function should take
any kind of SDF source, such an SDF file, an SDF object or an SDFset, 
and output a string representation of the descriptors. The toObject function
should take the same kind of input, but output the descriptors as an object.
The actual return value is a list containing the names of the compounds, and
the actual descriptor objects.

The second component to add is a transform that converts between string
and object representations of descriptors. In this case the toString function
takes descriptors in object form and returns a string representation for each.
The toObject function performs the inverse operation. It takes descriptors in string
form and returns them as objects. The objects returned by this function
will be exactly what is handed to the distance function, so you need to make sure that
the two match each other.




All \texttt{eiXXXX} methods accept a \texttt{measure} parameter.
A measure object handles dealing with the compound representations
and also computing distances between compounds.
It is a list with three fields, named: dbBuilder, dbSubset, and
db2dbDistance. Each of these is a function.

As an example, here is the default measure, which works for sdf
formated files and computes distances using atompair descriptors:
\begin{Scode}
 atompairMeasure = list(
	dbBuilder = function(input,output)
		batch_sdf_parse(input,output),
	dbSubset = function(db,iddb,output)
		db_subset(db,iddb,output),
	db2dbDistance = function(db,db2=NA,iddb1=NA,iddb2=NA,file=NA)
	{
		if(!is.na(file)){
			if(is.na(db2) && ! is.na(iddb1) && ! is.na(iddb2)){
				db2db_distance2file(db,iddb1,iddb2,file)
			}else if(!is.na(db2) &&  is.na(iddb1) &&  is.na(iddb2)){
				db2db_distance2file(db,db2,file)
			}else{
				stop("bad argument list")
			}
		}else{
			if(is.na(db2) && ! is.na(iddb1) && ! is.na(iddb2)){
				return(.Call("db2db_distance_iddb",as.character(db),as.character(iddb1),as.character(iddb2)))
			}else if(!is.na(db2) &&  is.na(iddb1) &&  is.na(iddb2)){
				return(.Call("db2db_distance_db",as.character(db),as.character(db2)))
			}else{
				stop("bad argument list\n")
			}
		}
	}
)
\end{Scode}
 

\texttt{DbBuilder} transforms the raw input file into whatever
format will be used by dbSubset and db2dbDistance. It should take
the name of an input file and the name of an output file to create.

\texttt{DbSubset} extracts a subset of compounds from one file and
puts them in another file. The compounds to extract are defined by 
an IDDB file. It should take the name of a compound
file, in the format output by dbBuilder, an IDDB file, and the name
of the output file

\texttt{Db2dbDistance} computes distances between compounds. There
are two ways to use this function. The first is to specify both
\texttt{db} and \texttt{db2}. This should compute all pairwise
distances between compounds in these two files. The second way is
to specify \texttt{db}, \texttt{iddb1}, and \texttt{iddb2}. In this
case distances are computed only between compounds given in the two
IDDB files. \texttt{db} should contain all compounds referenced by
the IDDB files. In both cases, the \texttt{file} can optionally be
given. If given, the output should be written to a file. The output
should be lines of whitespace separated numbers. Each line should
contain the distances of the first element of the first db against
each member of the second db. If \texttt{file} is not given, the
result should be returned as a matrix.


\begin{Scode}{echo=false,term=false}
   unlink("data",recursive=TRUE)
   unlink(runDir,recursive=TRUE)
\end{Scode}
\end{document}
